<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  <meta name="description"
        content="MAP-ADAPT: Real-Time Quality-Adaptive Semantic 3D Maps">
  <meta name="keywords" content="MAP-ADAPT: Real-Time Quality-Adaptive Semantic 3D Maps">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <title>MAP-ADAPT</title>

  <!-- Bootstrap -->
  <link rel="stylesheet" href="./static/css/bootstrap-4.4.1.css">

  <!-- Global site tag (gtag.js) - Google Analytics -->
  <!-- <script async src="https://www.googletagmanager.com/gtag/js?id=G-PYVRSFMDRL"></script>
  <script>
    window.dataLayer = window.dataLayer || [];

    function gtag() {
      dataLayer.push(arguments);
    }

    gtag('js', new Date());

    gtag('config', 'G-PYVRSFMDRL');
  </script> -->

  

  <link href="https://fonts.googleapis.com/css?family=Google+Sans|Noto+Sans|Castoro"
        rel="stylesheet">
  
  
  
  
  <link rel="stylesheet" href="./static/css/bulma.min.css">
  <link rel="stylesheet" href="./static/css/bulma-carousel.min.css">
  <link rel="stylesheet" href="./static/css/bulma-slider.min.css">
  <link rel="stylesheet" href="./static/css/fontawesome.all.min.css">
  <link rel="stylesheet"
        href="https://cdn.jsdelivr.net/gh/jpswalsh/academicons@1/css/academicons.min.css">
  <link rel="stylesheet" href="./static/css/index.css">
  <!-- <link rel="icon" href="./static/images/72.png"> -->

  

  <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.5.1/jquery.min.js"></script>
  <script defer src="./static/js/fontawesome.all.min.js"></script>
  <script src="./static/js/bulma-carousel.min.js"></script>
  <script src="./static/js/bulma-slider.min.js"></script>
  <script src="./static/js/index.js"></script>
  <script src="./static/js/app.js"></script>
  <script src="./static/js/video_comparison.js"></script>

  <link rel="stylesheet" href="./static/css/dics.original.css">
  <script src="./static/js/event_handler.js"></script>
  <script src="./static/js/dics.original.js"></script>
  


</head>
<body>


<section class="hero">
  <div class="hero-body">
    <div class="container is-max-desktop">
      <div class="columns is-centered">
        <div class="column has-text-centered">
          <h1 class="title is-1 publication-title">MAP-ADAPT</h1>
          <h2 class="title is-2 publication-title" style="margin-top: 0; margin-bottom: 0">Real-Time Quality-Adaptive Semantic 3D Maps</h2>

          <div class="column is-full_width">
            <h2 class="title is-4">European Conference on Computer Vision (<a href="https://eccv.ecva.net/">ECCV</a>) 2024</h2>
          </div>
          <div class="is-size-5 publication-authors">
            <span class="author-block">
              <a href="https://jianhao-zheng.github.io/">Jianhao Zheng</a><sup>1</sup></span>&nbsp;&nbsp;&nbsp;&nbsp;
              <span class="author-block">
                <a href="https://scholar.google.com/citations?user=U9-D8DYAAAAJ&hl=hu">Daniel Barath</a><sup>2</sup></span>&nbsp;&nbsp;&nbsp;&nbsp;
              <span class="author-block">
              <a href="https://people.inf.ethz.ch/marc.pollefeys/">Marc Pollefeys</a><sup>2,3</sup>&nbsp;&nbsp;&nbsp;&nbsp;
              <span class="author-block">
                <a href="https://ir0.github.io/">Iro Armeni</a><sup>1</sup>&nbsp;&nbsp;&nbsp;&nbsp;
            </span>
          </div>
          <div class="is-size-5 publication-authors">
            <span class="author-block"><sup>1</sup>Stanford University</span>&nbsp;&nbsp;&nbsp;&nbsp;
            <span class="author-block"><sup>2</sup>ETH ZÃ¼rich</span>&nbsp;&nbsp;
            <span class="author-block"><sup>3</sup>Microsoft</span>&nbsp;&nbsp;
          </div>

          <div class="column has-text-centered">
            <div class="publication-links">
              <!-- PDF Link. -->
              <span class="link-block">
                <a href="https://arxiv.org/abs/2406.05849"
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="fas fa-file-pdf"></i>
                  </span>
                  <span>Paper</span>
                </a>
              </span>

              <!-- Video Link. -->
              <span class="link-block">
                <a href="https://youtu.be/MB2D2j-rJ8E"
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="fab fa-youtube"></i>
                  </span>
                  <span>Video</span>
                </a>
              </span>
              <!-- Poster Link. -->
              <!-- <span class="link-block">
                <a href="media/nice-slam/poster_nice-slam.pdf"
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="fas fa-palette"></i>
                  </span>
                  <span>Poster</span>
                  </a>
              </span> -->

              <!-- Code Link. -->
              <span class="link-block">
                <a href="https://github.com/GradientSpaces/MAP-ADAPT"
                   class="external-link button is-normal is-rounded is-dark disabled">
                  <span class="icon">
                      <i class="fab fa-github"></i>
                  </span>
                  <span>Code</span>
                  </a>
              </span>

  

            </div>

          </div>
        </div>
      </div>
    </div>
  </div>
</section>


<section class="section">
  <div class="container is-max-desktop">
    <!-- Abstract. -->
    <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths">
        <h2 class="title is-3" style="margin-top: -30px">Abstract</h2>
        <div class="content has-text-justified">
          <p>
            Creating 3D semantic reconstructions of environments is fundamental to many applications, especially when related to autonomous agent operation (e.g. goal-oriented navigation or object interaction and manipulation).
            Commonly, 3D semantic reconstruction systems capture the entire scene in the same level of detail. 
            However, certain tasks (e.g. object interaction) require a fine-grained and high-resolution map, particularly if the objects to interact are of small size or intricate geometry. 
            In recent practice, this leads to the entire map being in the same high-quality resolution, which results in increased computational and storage costs. 
            To address this challenge, we propose <b>MAP-ADAPT</b>, a real-time method for quality-adaptive semantic 3D reconstruction using RGBD frames. 
            MAP-ADAPT is the first adaptive semantic 3D mapping algorithm that, unlike prior work, generates directly a single map with regions of different quality based on both the semantic information and the geometric complexity of the scene. 
            Leveraging a semantic SLAM pipeline for pose and semantic estimation, we achieve comparable or superior results to state-of-the-art methods on synthetic and real-world data, while significantly reducing storage and computation requirements.
          </p>
        </div>
      </div>
    </div>
    <!--/ Abstract. -->
    <!-- Paper video. -->
    
    <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths">
        <h2 class="title is-3">Video</h2>
        <div class="publication-video">
          <iframe src="https://www.youtube.com/embed/MB2D2j-rJ8E?rel=0&amp;showinfo=0"
                  frameborder="0" allow="autoplay; encrypted-media" allowfullscreen></iframe>
        </div>
      </div>
    </div>
   
    <!--/ Paper video. -->
  </div>
</section>




<section class="section">
  <div class="container is-max-desktop">

    <!-- Method. -->
    <div class="columns is-centered has-text-centered">
      <div class="column is-full-width">
        <h2 class="title is-3" style="margin-top: -20px">Method</h2>

        <img src="./resources/pipeline.jpg" class="center">
        <div class="content has-text-justified">
          <p style="margin-top: 30px">
            <b>MAP-ADAPT</b> (a) Given RGBD frames, we estimate (b-i) semantic segmentation and (b-iv) camera pose and compute (b-ii) geometric complexity. 
            (c-i) We integrate geometric and semantic information (b-iii) on the TSDF voxel map. 
            The geometric complexity and the semantic label will define the voxel size of that region of the map. 
            (c-ii) shows the multi-resolution mesh output. The adaptive structure we use is shown in (c-iii).
          </p>
        </div>

      </div>
    </div>
    <!--/ Animation. -->

  </div>
</section>

<section class="section">
  <div class="container is-max-desktop">

    <!-- Method. -->
    <div class="columns is-centered has-text-centered">
      <div class="column is-full-width">
        <h2 class="title is-3" style="margin-top: -20px">Qualitative Results</h2>

        <img src="./resources/qualitative.jpg" class="center"  style="margin-top: 20px;">

        <div class="content has-text-justified">
          <p style="margin-top: 30px">
            Top example is on <b>HSSD</b> and bottom one on <b>ScanNet</b> datasets. 
            Geometric and completion errors are shown as heatmaps; the darker the color, the closer to the GT geometry. 
            For semantic map, results are colorized per quality level; different semantics in the same quality level range from brighter to darker. 
            Another heatmap is used to show the estimated geometric complexity. 
            We highlight regions that are classified into high-quality semantics (<span style="color: red; font-style: italic;">red block</span>) or have large geometric variance (<span style="color: orange; font-style: italic;">orange block</span>).
          </p>
        </div>
      </div>
    </div>
    <!--/ Animation. -->

  </div>
</section>


<!-- <section class="section">
  <div class="container is-max-desktop">

    <div class="columns is-centered ">
      <div class="column is-full-width">
        <h2 class="title is-3 has-text-centered" style="margin-top: -30px">Additional Results</h2>

        <h3 class="title is-4">Replica Dataset</h3>

        <h3 class="title is-5">Reconstruction</h3>
        <div class="embed-responsive embed-responsive-16by9">

          <iframe style="clip-path: inset(1px 1px)" src="https://sketchfab.com/playlists/embed?collection=98147cf5e0e44418931f52a9646661fc&autostart=0" allow="accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture; fullscreen" mozallowfullscreen="true" webkitallowfullscreen="true" width="100%" height="100%" frameborder="0"></iframe>
        </div>

        <div style="height: 30px;"></div> 
        <h3 class="title is-5">Rendering</h3>
        <div class="container">
          <ul class="nav nav-tabs nav-fill nav-justified" id="replica-rendering">
              <li class="nav-item active">
                <a class="nav-link" onclick="replicaRenderingEvent(0)">room0</a>
              </li>
              <li class="nav-item">
                <a class="nav-link" onclick="replicaRenderingEvent(1)">room1</a>
              </li>
              <li class="nav-item">
                <a class="nav-link" onclick="replicaRenderingEvent(2)">room2</a>
              </li>
              <li class="nav-item">
                <a class="nav-link" onclick="replicaRenderingEvent(3)">office0</a>
              </li>
              <li class="nav-item">
                <a class="nav-link" onclick="replicaRenderingEvent(4)">office1</a>
              </li>
              <li class="nav-item">
                <a class="nav-link" onclick="replicaRenderingEvent(5)">office2</a>
              </li>
              <li class="nav-item">
                <a class="nav-link" onclick="replicaRenderingEvent(6)">office3</a>
              </li>
              <li class="nav-item">
                <a class="nav-link" onclick="replicaRenderingEvent(7)">office4</a>
              </li>
          </ul>
          <div class="b-dics" style="width: 1000px; font-weight: 600;">
              <img src="resources/rendering/replica/room0_nice.jpg" alt="NICE-SLAM">
              <img src="resources/rendering/replica/room0_dim.jpg" alt="DIM-SLAM">
              <img src="resources/rendering/replica/room0_droid.jpg" alt="DROID-SLAM">
              <img src="resources/rendering/replica/room0_ours.png" alt="NICER-SLAM (Ours)">
              <img src="resources/rendering/replica/room0_gt.png" alt="GT">
          </div>
        </div>
        
        <div style="height: 50px;"></div> 
        <h3 class="title is-4">7-Scenes Dataset</h3>

        
        <div class="container">
          <div class="b-dics" style="width: 1000px; font-weight: 600;">
              <img src="resources/recon/7scenes/7scenes_office_nice_normal.jpg" alt="NICE-SLAM">
              <img src="resources/recon/7scenes/7scenes_office_nerfslam_normal.jpg" alt="NeRF-SLAM">
              <img src="resources/recon/7scenes/7scenes_office_dim_normal.jpg" alt="DIM-SLAM">
              <img src="resources/recon/7scenes/7scenes_office_droid_normal.jpg" alt="DROID-SLAM">
              <img src="resources/recon/7scenes/7scenes_office_ours_normal.jpg" alt="NICER-SLAM (Ours)">
              <img src="resources/recon/7scenes/7scenes_office_gt_normal.jpg" alt="GT">
          </div>
        </div>
        
        
       
        <div style="height: 50px;"></div> 
        <h3 class="title is-4">Self-Captured Outdoor Dataset</h3>

        <h3 class="title is-5">Rendering</h3>
        
          <div class="b-dics" style="width: 1000px; font-weight: 600;">
              <img src="resources/rendering/self/azure_15_colmap.jpg" alt="COLMAP">
              <img src="resources/rendering/self/azure_15_tandem.jpg" alt="TANDEM">
              <img src="resources/rendering/self/azure_15_nerfslam.jpg" alt="NeRF-SLAM">
              <img src="resources/rendering/self/azure_15_droid.jpg" alt="DROID-SLAM">
              <img src="resources/rendering/self/azure_15_ours.jpg" alt="NICER-SLAM (Ours)">
          </div>

        <div style="height: 50px;"></div>
        <h3 class="title is-5">Reconstruction</h3>

        <div class="b-dics" style="width: 1000px; font-weight: 600;">
          <img src="resources/recon/self/azure_11_colmap_normal.jpg" alt="COLMAP">
          <img src="resources/recon/self/azure_11_tandem_normal.jpg" alt="TANDEM">
          <img src="resources/recon/self/azure_11_nerfslam_normal.jpg" alt="NeRF-SLAM">
          <img src="resources/recon/self/azure_11_droid_normal.jpg" alt="DROID-SLAM">
          <img src="resources/recon/self/azure_11_ours_normal.jpg" alt="NICER-SLAM (Ours)">
      </div>

      </div>
    </div>

  </div>
</section>  -->



<!-- <section class="section" id="BibTeX">
  <div class="container is-max-desktop content">
    <h2 class="title">BibTeX</h2>
    <pre><code>@inproceedings{Zhu2023NICER,
  author={Zhu, Zihan and Peng, Songyou and Larsson, Viktor and Cui, Zhaopeng and Oswald, Martin R and Geiger, Andreas and Pollefeys, Marc},
  title     = {NICER-SLAM: Neural Implicit Scene Encoding for RGB SLAM},
  booktitle = {International Conference on 3D Vision (3DV)},
  month     = {March},
  year      = {2024},
}</code></pre>
  </div>
</section> -->

<!-- <section class="section" id="Acknowledgements">
  <div class="container is-max-desktop content">
    <h2 class="title">Acknowledgements</h2>
    This project is partially supported by the SONY Research Award Program and a research grant by FIFA. The authors thank the Max Planck ETH Center for Learning Systems (CLS) for supporting Songyou Peng and the strategic research project ELLIIT for supporting Viktor Larsson. We thank Zehao Yu, Yiming Zhao, Weicai Ye, Boyang Sun, Jianhao Zheng, and Heng Li for their helpful discussion.
  </div>
</section> -->

<!-- <section class="section" id="References">
  <div class="container is-max-desktop content">

        <h3 class="title is-4">References</h3>
        <div class="content has-text-justified">
          <ul>
            <li>
              <a href="https://repo-sam.inria.fr/fungraph/3d-gaussian-splatting/" target="_blank">3D Gaussian Splatting for Real-Time Radiance Field Rendering</a>
            </li>
            <li>
              <a href="https://www.cs.umd.edu/~zwicker/publications/EWASplatting-TVCG02.pdf" target="_blank">EWA Splatting</a>
            </li>
          </ul>
        </div>
      </div>
</section> -->


<footer class="footer">
  <div class="container">
    <div class="content has-text-centered">
    </div>
    <div class="columns is-centered">
      <div class="column is-8">
        <div class="content">
          <p>
            This website is licensed under a <a rel="license" href="http://creativecommons.org/licenses/by-sa/4.0/">Creative
            Commons Attribution-ShareAlike 4.0 International License</a>.
            This webpage template is from <a href="https://github.com/nerfies/nerfies.github.io">Nerfies</a>. 
            We sincerely thank <a href="https://keunhong.com/">Keunhong Park</a> for developing and open-sourcing this template. 
            <!-- The video comparison with sliding bar is from <a href="https://dorverbin.github.io/refnerf/">Ref-NeRF</a>.  -->
            <!-- The image comparison with sliding bar is from <a href="https://research.nvidia.com/labs/dir/neuralangelo/">Neuralangelo</a>.  -->
          </p>
        </div>
      </div>
          <p></p>
        </div>
      </div>
</footer>

</body>
</html>
